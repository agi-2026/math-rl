# SFT Configuration for Qwen3-4B via Tinker
# Phase 2: Supervised Fine-Tuning on teacher-distilled reasoning traces

model_name: Qwen/Qwen3-4B
lora_rank: 64

# Optimizer (linear decay from this LR to 0)
learning_rate: 2.0e-5

# Training
num_epochs: 3
batch_size: 128         # datums per forward_backward call
max_length: 4096        # max sequence length (truncate longer)
train_on_what: all_assistant_messages

# Logging & checkpointing
save_every: 20          # save every N steps
